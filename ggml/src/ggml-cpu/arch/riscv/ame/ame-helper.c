#include "ame.h"
#include "ggml-impl.h"
#include "ggml-quants.h"
#include <math.h>
#include <assert.h>
#include <stdlib.h>

// Quantize a row of F32 values to Q8_0 format
// Renamed from static quantize_row_f32_to_q8_0 in ame-matmul.c
void ggml_ame_quantize_row_f32_to_q8_0(const float * x, void * vy, int k) {
    block_q8_0 * y = (block_q8_0 *)vy;
    assert(k % 32 == 0);
    const int nb = k / 32;

    for (int i = 0; i < nb; i++) {
        float amax = 0.0f;
        for (int j = 0; j < 32; j++) {
            const float v = x[i * 32 + j];
            const float av = fabsf(v);
            if (av > amax) amax = av;
        }

        const float d = amax / 127.0f;
        const float id = d ? 1.0f / d : 0.0f;

        y[i].d = GGML_FP32_TO_FP16(d);

        for (int j = 0; j < 32; j++) {
            const float x0 = x[i * 32 + j] * id;
            y[i].qs[j] = roundf(x0);
        }
    }
}

// Repacks Q4_0 blocks into AME-optimized format
// Unpacks 4-bit nibbles into 8-bit integers effectively creating Q8_0-like layout but with 4-bit range
void ggml_ame_repack_q4_0(
    void * dst,              // Output: block_q4_0_ame array
    const void * src,        // Input: block_q4_0 array
    int64_t nblocks          // Number of Q4_0 blocks
) {
    const block_q4_0 * restrict src_blocks = (const block_q4_0 *)src;
    block_q4_0_ame * restrict dst_blocks = (block_q4_0_ame *)dst;

    for (int64_t i = 0; i < nblocks; i++) {
        dst_blocks[i].d = src_blocks[i].d;

        for (int j = 0; j < 16; j++) {
            uint8_t v = src_blocks[i].qs[j];
            // Lower nibble
            dst_blocks[i].qs[2*j]     = (int8_t)(v & 0x0F) - 8;
            // Upper nibble
            dst_blocks[i].qs[2*j + 1] = (int8_t)((v >> 4) & 0x0F) - 8;
        }
    }
}
